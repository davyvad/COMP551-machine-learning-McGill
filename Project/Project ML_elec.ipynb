{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,argparse\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import BernoulliNB,MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import  VotingClassifier, BaggingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon elec dataset of reviews.\n",
    "### 1- negative review \n",
    "### 2- positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of critics:  25000 25000\n",
      "2\n",
      " why this rating some years ago when bought my hv20 did lot of research on tapes and the consensus overwhelmingly pointed to the panasonic amq family so far with over 50 tapes used am happy camper indeed no dropouts and great quality am true believer now and hence the 5-star `` love it `` rating tape types irrespective of the tape you decide to use learned that it was more important to be loyal to the type of lubricant used referred to by my friends as wet or dry tapes the panasonic belongs to the dry type family whereas sony tapes use wet lubricant for instance panasonic claims that this tape uses `` .. dry type lubricant that causes less video head wear 4m after 500h it also prevents head clogs and extends head life `` while some on the net argue that this distinction is an urban myth decided to trust my professional friends on this issue this difference is not material until you switch between the two types which can lead to clogged video heads archival rely very heavily on tape as an archival mechanism for all my hd masters hence my decision to go with the amq series over the pq series which are bit cheaper happy recording damodar\n",
      "2\n",
      " bought this backpack for travel vacation purposes it worked out great the bag is not too small and not too big was suprised how many lens and accessories could jam in here put my rebel xt tamron 28-75mm lens also put additional lens in the bag canon 28-135 is 17-55mm and 50mm oh and 430 flash that was all fitted in the bottom section only you still have plenty of room up top for accessories cf card lens cleaning kit etc also it came in handy as shopping bag of course did n't carry all lenses with me at all times just the ones was gon na use that day the bag is very comfortable to wear due to the fact that the shoulder pads were made of gel all in all it was very balance backback that was versatile and looks great too the only negative thing have to say about this backpack is that if you want to get to your camera in an instant forget it you have to take of the bag set it down somewhere then unclip and unzipper it before you can get you camera out then again your camera is very safe in here and if you want fast access get sling backpack or wear the camera around you neck\n",
      "2\n",
      " purchased this so could have power for my gps on my snowmobile if you do n't have cigarette plug on yours go to your local electronics store and get yourself bridge rectifier cut the plug off of this and connect to the rectifier tap into 12 vac and ground on the sled for the other connectors on the rectifier and you 've got power you do still need batteries because the voltage gets weak at idle but there is plenty off idle get the bicycle mount for gps to mount on handlebars been using this setup for few years works great and is smart idea in unfamiliar territory\n",
      "Total number of critics:  25000 25000\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset:\n",
    "train_reviews = []\n",
    "train_labels =[]\n",
    "test_reviews = []\n",
    "test_labels =[]\n",
    "lemm = WordNetLemmatizer()\n",
    "\n",
    "stops = stopwords.words('english')\n",
    "def load_dataset(review_path, label_path, all_reviews, all_labels):\n",
    "\n",
    "        \n",
    "    # Loading spam-emails:\n",
    "    with open(review_path, 'r') as f:\n",
    "        for line in f.readlines():  \n",
    "            #print(line)\n",
    "            #line = line.decode('utf8')\n",
    "            \n",
    "            # Preprocess\n",
    "            # Convert all line in lower case. Tokenize the review\n",
    "            line= line.replace(\":-)\", \"%smile\")\n",
    "            line= line.replace(\":-(\", \"%sad\")\n",
    "            line= word_tokenize(line.lower())\n",
    "            clean =\"\"\n",
    "            #line = [word for word in line if word not in stops]\n",
    "            #line=[lemm.lemmatize(word) for word in line]\n",
    "    \n",
    "            #remove words of lenght 1\n",
    "            line= \" \".join([word for word in line if  len(word)>1]) # and not word.isdigit()])\n",
    "            #print(line)\n",
    "            all_reviews.append(line)\n",
    "        f.close()\n",
    "        \n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f.readlines():  \n",
    "            all_labels.append(line)\n",
    "        f.close()\n",
    "\n",
    "    print (\"Total number of critics: \", len(all_reviews), len(all_labels))\n",
    "path = \"./elec/elec-25k-train.txt.tok\"\n",
    "label_path = \"./elec/elec-25k-train.cat\"\n",
    "\n",
    "\n",
    "load_dataset(path, label_path,train_reviews , train_labels)\n",
    "for i in range(3):\n",
    "    print(train_labels[i], train_reviews[i])\n",
    "path = \"./elec/elec-test.txt.tok\"\n",
    "label_path = \"./elec/elec-test.cat\"\n",
    "\n",
    "load_dataset(path, label_path,test_reviews , test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 25000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_reviews), len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of critics:  5000 5000\n"
     ]
    }
   ],
   "source": [
    "train_reviews = []\n",
    "train_labels =[]\n",
    "\n",
    "path = \"./elec/elec-05k-train.txt.tok\"\n",
    "label_path = \"./elec/elec-05k-train.cat\"\n",
    "load_dataset(path, label_path,train_reviews , train_labels)\n",
    "\n",
    "#vectorizer = CountVectorizer()\n",
    "vectorizer = TfidfVectorizer( min_df=2, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1)\n",
    "X = vectorizer.fit_transform(train_reviews)\n",
    "X_test= vectorizer.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For classifier:  <class 'sklearn.svm.classes.LinearSVC'> :\n",
      "The scores on cross validation are: [0.8096 0.8008 0.776  0.784 ]\n",
      "Accuracy: 0.79 (+/- 0.03)\n",
      "With the following params : {'C': 0.008, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.7926\n",
      "The scores on cross validation are: [0.8424 0.8208 0.8184 0.828 ]\n",
      "Accuracy: 0.83 (+/- 0.02)\n",
      "With the following params : {'C': 0.008, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.8274\n",
      "The scores on cross validation are: [0.8096 0.8008 0.776  0.784 ]\n",
      "Accuracy: 0.79 (+/- 0.03)\n",
      "With the following params : {'C': 0.01, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.7926\n",
      "The scores on cross validation are: [0.8464 0.8224 0.82   0.8288]\n",
      "Accuracy: 0.83 (+/- 0.02)\n",
      "With the following params : {'C': 0.01, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.8293999999999999\n",
      "The scores on cross validation are: [0.8096 0.8008 0.776  0.784 ]\n",
      "Accuracy: 0.79 (+/- 0.03)\n",
      "With the following params : {'C': 0.02, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.7926\n",
      "The scores on cross validation are: [0.8512 0.832  0.8312 0.84  ]\n",
      "Accuracy: 0.84 (+/- 0.02)\n",
      "With the following params : {'C': 0.02, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.8385999999999999\n",
      "The scores on cross validation are: [0.8504 0.8328 0.836  0.8448]\n",
      "Accuracy: 0.84 (+/- 0.01)\n",
      "With the following params : {'C': 0.1, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.841\n",
      "The scores on cross validation are: [0.86   0.8584 0.8584 0.86  ]\n",
      "Accuracy: 0.86 (+/- 0.00)\n",
      "With the following params : {'C': 0.1, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.8592\n",
      "The scores on cross validation are: [0.8616 0.8696 0.8608 0.864 ]\n",
      "Accuracy: 0.86 (+/- 0.01)\n",
      "With the following params : {'C': 0.5, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.864\n",
      "The scores on cross validation are: [0.8536 0.8608 0.8712 0.864 ]\n",
      "Accuracy: 0.86 (+/- 0.01)\n",
      "With the following params : {'C': 0.5, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.8623999999999999\n",
      "The scores on cross validation are: [0.8584 0.86   0.8648 0.8664]\n",
      "Accuracy: 0.86 (+/- 0.01)\n",
      "With the following params : {'C': 1.0, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.8623999999999999\n",
      "The scores on cross validation are: [0.8552 0.8552 0.8632 0.86  ]\n",
      "Accuracy: 0.86 (+/- 0.01)\n",
      "With the following params : {'C': 1.0, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.8583999999999999\n",
      "\n",
      "Final best params:  {'C': 0.5, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 0} \n",
      "Best mean accuracy score on cross validation:  0.864 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "#combination of l1 and squared_hinge / hinge is not supported\n",
    "svm_param= ParameterGrid([{'random_state':[0],'loss':['hinge','squared_hinge'],'C':[0.008,0.01,0.02,.1, .5 , 1.0], 'penalty':['l2']}])\n",
    "#svc_param = ParameterGrid({'random_state':[0],'kernel':['rbf','poly'],'C':[.5, 1.0,2.0]})\n",
    "\n",
    "best_param_model=[]\n",
    "#get the best params for each model on validation set\n",
    "def get_best_param(class_and_param, train_vectors, train_labels):  #, val_vectors, val_labels):\n",
    "    for (classifier, params) in class_and_param:\n",
    "        print(\"For classifier: \",classifier,\":\")\n",
    "        best_mean_acc = 0\n",
    "        best_params=None\n",
    "        for param in params:\n",
    "            #act_score = compute_f1(classifier(**param), train_vectors, train_labels,val_vectors, val_labels)\n",
    "            clf = classifier(**param)\n",
    "            scores = cross_val_score(clf, train_vectors, train_labels, cv=4)\n",
    "            print(\"The scores on cross validation are:\", scores)                                              \n",
    "\n",
    "            print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "            mean_acc = scores.mean()\n",
    "            if(mean_acc >best_mean_acc):\n",
    "                best_mean_acc = mean_acc\n",
    "                best_params= param\n",
    "            print(\"With the following params :\", param)\n",
    "            print(\"Mean Accuracy achieved : \", mean_acc)\n",
    "        best_param_model.append(best_params)     \n",
    "        print(\"\\nFinal best params: \", best_params, \"\\nBest mean accuracy score on cross validation: \", best_mean_acc, \"\\n\")\n",
    "        \n",
    "class_and_param= [(LinearSVC, svm_param)]\n",
    "get_best_param(class_and_param,X, train_labels) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram\n",
      "\n",
      "SVM\tAccuracy of test set: (train on 25K)  0.88644\n"
     ]
    }
   ],
   "source": [
    "print (\"Unigram\\n\")\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer = TfidfVectorizer( min_df=2, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1)\n",
    "X = vectorizer.fit_transform(train_reviews)\n",
    "    \n",
    "#print(vectorizer.get_feature_names())\n",
    "#print(X.toarray())  \n",
    "# Train SVM:\n",
    "classifier =LinearSVC(C=0.5, loss='hinge' ,random_state=0)\n",
    "classifier.fit(X, train_labels)\n",
    "\n",
    "X_test= vectorizer.transform(test_reviews)\n",
    "pred = classifier.predict(X_test)\n",
    "print (\"SVM\\tAccuracy of test set: (train on 25K) \", sklearn.metrics.accuracy_score(test_labels, pred))  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram\n",
      "\n",
      "For classifier:  <class 'sklearn.naive_bayes.MultinomialNB'> :\n",
      "The scores on cross validation are: [0.825054   0.82397408 0.82273164]\n",
      "Accuracy: 0.82 (+/- 0.00)\n",
      "With the following params : {'alpha': 0.0001}\n",
      "Mean Accuracy achieved :  0.8239199049385699\n",
      "The scores on cross validation are: [0.84293257 0.84209263 0.84013442]\n",
      "Accuracy: 0.84 (+/- 0.00)\n",
      "With the following params : {'alpha': 0.001}\n",
      "Mean Accuracy achieved :  0.8417198731638674\n",
      "The scores on cross validation are: [0.86681066 0.86537077 0.86053769]\n",
      "Accuracy: 0.86 (+/- 0.01)\n",
      "With the following params : {'alpha': 0.01}\n",
      "Mean Accuracy achieved :  0.8642397038385753\n",
      "The scores on cross validation are: [0.88132949 0.88312935 0.88118099]\n",
      "Accuracy: 0.88 (+/- 0.00)\n",
      "With the following params : {'alpha': 0.1}\n",
      "Mean Accuracy achieved :  0.8818799440835899\n",
      "The scores on cross validation are: [0.88396928 0.8887689  0.88514162]\n",
      "Accuracy: 0.89 (+/- 0.00)\n",
      "With the following params : {'alpha': 0.3}\n",
      "Mean Accuracy achieved :  0.88595993453505\n",
      "The scores on cross validation are: [0.887449   0.89044876 0.88526164]\n",
      "Accuracy: 0.89 (+/- 0.00)\n",
      "With the following params : {'alpha': 0.6}\n",
      "Mean Accuracy achieved :  0.8877198033470813\n",
      "The scores on cross validation are: [0.88732901 0.88936885 0.88538166]\n",
      "Accuracy: 0.89 (+/- 0.00)\n",
      "With the following params : {'alpha': 1}\n",
      "Mean Accuracy achieved :  0.8873598417455456\n",
      "The scores on cross validation are: [0.88912887 0.88780898 0.88070091]\n",
      "Accuracy: 0.89 (+/- 0.01)\n",
      "With the following params : {'alpha': 2}\n",
      "Mean Accuracy achieved :  0.8858795857061152\n",
      "The scores on cross validation are: [0.88768898 0.88552916 0.8787806 ]\n",
      "Accuracy: 0.88 (+/- 0.01)\n",
      "With the following params : {'alpha': 3}\n",
      "Mean Accuracy achieved :  0.8839995824817931\n",
      "The scores on cross validation are: [0.88468922 0.88096952 0.87241959]\n",
      "Accuracy: 0.88 (+/- 0.01)\n",
      "With the following params : {'alpha': 5}\n",
      "Mean Accuracy achieved :  0.8793594448113858\n",
      "\n",
      "Final best params:  {'alpha': 0.6} \n",
      "Best mean accuracy score on cross validation:  0.8877198033470813 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Bigram\\n\")\n",
    "\n",
    "#vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=2, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1)\n",
    "X = vectorizer.fit_transform(train_reviews)\n",
    "    \n",
    "#print(vectorizer.get_feature_names())\n",
    "#print(X.toarray())  \n",
    "# Train SVM:\n",
    "\n",
    "X_test= vectorizer.transform(test_reviews)\n",
    "#pred = classifier.predict(X_test)\n",
    "#print (\"SVM\\tAccuracy of validation set: \", sklearn.metrics.accuracy_score(test_labels, pred))  \n",
    "    \n",
    "best_param_model=[]\n",
    "#get the best params for each model on validation set\n",
    "def get_best_param(class_and_param, train_vectors, train_labels):  #, val_vectors, val_labels):\n",
    "    for (classifier, params) in class_and_param:\n",
    "        print(\"For classifier: \",classifier,\":\")\n",
    "        best_mean_acc = 0\n",
    "        best_params=None\n",
    "        for param in params:\n",
    "            #act_score = compute_f1(classifier(**param), train_vectors, train_labels,val_vectors, val_labels)\n",
    "            clf = classifier(**param)\n",
    "            scores = cross_val_score(clf, train_vectors, train_labels, cv=3)\n",
    "            print(\"The scores on cross validation are:\", scores)                                              \n",
    "\n",
    "            print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "            mean_acc = scores.mean()\n",
    "            if(mean_acc >best_mean_acc):\n",
    "                best_mean_acc = mean_acc\n",
    "                best_params= param\n",
    "            print(\"With the following params :\", param)\n",
    "            print(\"Mean Accuracy achieved : \", mean_acc)\n",
    "        best_param_model.append(best_params)     \n",
    "        print(\"\\nFinal best params: \", best_params, \"\\nBest mean accuracy score on cross validation: \", best_mean_acc, \"\\n\")\n",
    "        \n",
    "nb_params = ParameterGrid({'alpha':[1e-4, 1e-3,0.01,0.1,0.3,0.6,1,2,3,5]})\n",
    "classifiers = [(MultinomialNB, nb_params)] #, (LinearSVC, svm_param)]\n",
    "get_best_param(classifiers,X, train_labels) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram with following parameters:\n",
      "\n",
      "MultinomialNB(alpha=0.4, class_prior=None, fit_prior=True)\n",
      "SVM\tAccuracy of validation set:  0.87216\n"
     ]
    }
   ],
   "source": [
    "print (\"Bigram with following parameters:\\n\")\n",
    "classifier = LinearSVC(C=1, loss='squared_hinge', penalty='l2', random_state=0)\n",
    "classifier = MultinomialNB(alpha=0.4)\n",
    "print(classifier)\n",
    "\n",
    "#Vectorize\n",
    "vectorizer2 = CountVectorizer(ngram_range=(1, 2))\n",
    "#vectorizer2 = TfidfVectorizer(ngram_range=(1, 2), min_df=2, strip_accents='unicode', use_idf=1,\n",
    " #              smooth_idf=1, sublinear_tf=1)\n",
    "X = vectorizer2.fit_transform(train_reviews)\n",
    "    \n",
    "# Train SVM:\n",
    "classifier.fit(X, train_labels)\n",
    "\n",
    "X_test= vectorizer2.transform(test_reviews)\n",
    "pred = classifier.predict(X_test)\n",
    "print (\"SVM\\tAccuracy of validation set: \", sklearn.metrics.accuracy_score(test_labels, pred))  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram\n",
      "\n",
      "Total number of critics:  5000 5000\n",
      "For classifier:  <class 'sklearn.naive_bayes.BernoulliNB'> :\n",
      "The scores on cross validation are: [0.81594724 0.82472989 0.83733493]\n",
      "Accuracy: 0.83 (+/- 0.02)\n",
      "With the following params : {'alpha': 0.0001}\n",
      "Mean Accuracy achieved :  0.8260040227122024\n",
      "The scores on cross validation are: [0.82434053 0.83133253 0.83973589]\n",
      "Accuracy: 0.83 (+/- 0.01)\n",
      "With the following params : {'alpha': 0.001}\n",
      "Mean Accuracy achieved :  0.831802984982962\n",
      "The scores on cross validation are: [0.83513189 0.83913565 0.84273709]\n",
      "Accuracy: 0.84 (+/- 0.01)\n",
      "With the following params : {'alpha': 0.01}\n",
      "Mean Accuracy achieved :  0.8390015478613507\n",
      "The scores on cross validation are: [0.85191847 0.82653061 0.82653061]\n",
      "Accuracy: 0.83 (+/- 0.02)\n",
      "With the following params : {'alpha': 0.1}\n",
      "Mean Accuracy achieved :  0.8349932299058712\n",
      "The scores on cross validation are: [0.85791367 0.82292917 0.81452581]\n",
      "Accuracy: 0.83 (+/- 0.04)\n",
      "With the following params : {'alpha': 0.3}\n",
      "Mean Accuracy achieved :  0.8317895503525151\n",
      "The scores on cross validation are: [0.85851319 0.81152461 0.79771909]\n",
      "Accuracy: 0.82 (+/- 0.05)\n",
      "With the following params : {'alpha': 0.6}\n",
      "Mean Accuracy achieved :  0.822585628975811\n",
      "The scores on cross validation are: [0.86211031 0.80612245 0.78451381]\n",
      "Accuracy: 0.82 (+/- 0.07)\n",
      "With the following params : {'alpha': 1}\n",
      "Mean Accuracy achieved :  0.8175821887508001\n",
      "The scores on cross validation are: [0.86510791 0.79651861 0.76530612]\n",
      "Accuracy: 0.81 (+/- 0.08)\n",
      "With the following params : {'alpha': 2}\n",
      "Mean Accuracy achieved :  0.8089775478536739\n",
      "The scores on cross validation are: [0.86810552 0.7785114  0.73889556]\n",
      "Accuracy: 0.80 (+/- 0.11)\n",
      "With the following params : {'alpha': 3}\n",
      "Mean Accuracy achieved :  0.7951708261242146\n",
      "\n",
      "Final best params:  {'alpha': 0.01} \n",
      "Best mean accuracy score on cross validation:  0.8390015478613507 \n",
      "\n",
      "For classifier:  <class 'sklearn.svm.classes.LinearSVC'> :\n",
      "The scores on cross validation are: [0.83093525 0.80612245 0.74369748]\n",
      "Accuracy: 0.79 (+/- 0.07)\n",
      "With the following params : {'C': 0.008, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.79358505992325\n",
      "The scores on cross validation are: [0.83872902 0.82112845 0.83313325]\n",
      "Accuracy: 0.83 (+/- 0.01)\n",
      "With the following params : {'C': 0.008, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.8309969071561478\n",
      "The scores on cross validation are: [0.83093525 0.80612245 0.74369748]\n",
      "Accuracy: 0.79 (+/- 0.07)\n",
      "With the following params : {'C': 0.01, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.79358505992325\n",
      "The scores on cross validation are: [0.83932854 0.82112845 0.83553421]\n",
      "Accuracy: 0.83 (+/- 0.02)\n",
      "With the following params : {'C': 0.01, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.8319970674120967\n",
      "The scores on cross validation are: [0.83093525 0.80612245 0.74369748]\n",
      "Accuracy: 0.79 (+/- 0.07)\n",
      "With the following params : {'C': 0.02, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.79358505992325\n",
      "The scores on cross validation are: [0.84172662 0.82232893 0.83853541]\n",
      "Accuracy: 0.83 (+/- 0.02)\n",
      "With the following params : {'C': 0.02, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.834196988147777\n",
      "The scores on cross validation are: [0.83093525 0.80612245 0.77310924]\n",
      "Accuracy: 0.80 (+/- 0.05)\n",
      "With the following params : {'C': 0.1, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.8033889814918774\n",
      "The scores on cross validation are: [0.86091127 0.84153661 0.84813926]\n",
      "Accuracy: 0.85 (+/- 0.02)\n",
      "With the following params : {'C': 0.1, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.8501957137771176\n",
      "The scores on cross validation are: [0.8735012  0.85114046 0.85354142]\n",
      "Accuracy: 0.86 (+/- 0.02)\n",
      "With the following params : {'C': 0.5, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.859394357263289\n",
      "The scores on cross validation are: [0.87589928 0.86254502 0.87094838]\n",
      "Accuracy: 0.87 (+/- 0.01)\n",
      "With the following params : {'C': 0.5, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.8697975593114945\n",
      "The scores on cross validation are: [0.88609113 0.87755102 0.88055222]\n",
      "Accuracy: 0.88 (+/- 0.01)\n",
      "With the following params : {'C': 1.0, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.88139812279828\n",
      "The scores on cross validation are: [0.8794964  0.87154862 0.87995198]\n",
      "Accuracy: 0.88 (+/- 0.01)\n",
      "With the following params : {'C': 1.0, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 0}\n",
      "Mean Accuracy achieved :  0.8769990010392646\n",
      "\n",
      "Final best params:  {'C': 1.0, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 0} \n",
      "Best mean accuracy score on cross validation:  0.88139812279828 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Trigram\\n\")\n",
    "train_reviews = []\n",
    "train_labels =[]\n",
    "\n",
    "path = \"./elec/elec-05k-train.txt.tok\"\n",
    "label_path = \"./elec/elec-05k-train.cat\"\n",
    "load_dataset(path, label_path,train_reviews , train_labels)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=2, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1)\n",
    "X = vectorizer.fit_transform(train_reviews)\n",
    "    \n",
    "#print(vectorizer.get_feature_names())\n",
    "#print(X.toarray())  \n",
    "# Train SVM:\n",
    "\n",
    "X_test= vectorizer.transform(test_reviews)\n",
    "#pred = classifier.predict(X_test)\n",
    "#print (\"SVM\\tAccuracy of validation set: \", sklearn.metrics.accuracy_score(test_labels, pred))  \n",
    "    \n",
    "best_param_model=[]\n",
    "nb_params = ParameterGrid({'alpha':[1e-4, 1e-3,0.01,0.1,0.3,0.6,1,2,3]})\n",
    "classifiers = [(BernoulliNB, nb_params), (LinearSVC, svm_param)]\n",
    "get_best_param(classifiers,X, train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram with following parameters:\n",
      "\n",
      "MultinomialNB(alpha=0.4, class_prior=None, fit_prior=True)\n",
      "SVM\tAccuracy of validation set:  0.88364\n"
     ]
    }
   ],
   "source": [
    "print (\"Trigram with following parameters:\\n\")\n",
    "classifier = LinearSVC(C=1, loss='hinge', penalty='l2', random_state=0)\n",
    "#classifier = BernoulliNB(alpha=0.1)\n",
    "classifier = MultinomialNB(alpha=0.4)\n",
    "\n",
    "print(classifier)\n",
    "#Vectorize\n",
    "vectorizer2 = CountVectorizer(ngram_range=(1, 3))\n",
    "#vectorizer2 = TfidfVectorizer(ngram_range=(1, 3), min_df=2, strip_accents='unicode', use_idf=1,\n",
    " #              smooth_idf=1, sublinear_tf=1)\n",
    "X = vectorizer2.fit_transform(train_reviews)\n",
    "\n",
    "bagclf=BaggingClassifier(classifier,max_samples=0.7)\n",
    "bagclf.fit(X, train_labels)\n",
    "\n",
    "# Train SVM:\n",
    "classifier.fit(X, train_labels)\n",
    "\n",
    "X_test= vectorizer2.transform(test_reviews)\n",
    "pred = classifier.predict(X_test)\n",
    "print (\"SVM\\tAccuracy of validation set: \", sklearn.metrics.accuracy_score(test_labels, pred))  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.26964051, -0.57380242,  1.14079745,  0.93619764,  1.05929235,\n",
       "        0.37334154,  2.41763543,  1.96162886,  2.6044915 ,  3.10598822,\n",
       "        1.68469341, -1.17283117,  1.22145118,  1.72380054, -0.61452391,\n",
       "        0.67288485, -1.50891888,  0.71395862, -1.15122455, -3.07094113])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifier.decision_function(test_reviews)\n",
    "test_reviews\n",
    "import pandas as pd\n",
    "#dat1 = pd.DataFrame({'data': X_test})\n",
    "#dat2 = pd.DataFrame({'labels': test_labels})\n",
    "\n",
    "#dat=dat1.join(dat2)\n",
    "#print(dat.values)\n",
    "classifier.decision_function(X_test)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1) \n",
    "X = vectorizer.fit_transform(train_reviews)\n",
    "clf1 = LogisticRegression(solver='lbfgs',C=1, random_state=1)\n",
    "clf2 = LinearSVC(C=0.01)\n",
    "clf3 = MultinomialNB(alpha=0.6)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('svm', clf2), ('nb', clf3)], voting='hard')# ('lr', clf1),\n",
    "eclf1 = eclf1.fit(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidvalensi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88016"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test= vectorizer.transform(test_reviews)\n",
    "\n",
    "accuracy_score(eclf1.predict(X_test), test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For classifier:  <class 'sklearn.linear_model.logistic.LogisticRegression'> :\n",
      "The scores on cross validation are: [0.79733621 0.79649628 0.78948632]\n",
      "Accuracy: 0.79 (+/- 0.01)\n",
      "With the following params : {'C': 0.0001, 'solver': 'newton-cg'}\n",
      "Mean Accuracy achieved :  0.7944396037371259\n",
      "The scores on cross validation are: [0.79721622 0.79649628 0.78948632]\n",
      "Accuracy: 0.79 (+/- 0.01)\n",
      "With the following params : {'C': 0.0001, 'solver': 'lbfgs'}\n",
      "Mean Accuracy achieved :  0.79439960693687\n",
      "The scores on cross validation are: [0.79601632 0.79781617 0.78900624]\n",
      "Accuracy: 0.79 (+/- 0.01)\n",
      "With the following params : {'C': 0.0001, 'solver': 'liblinear'}\n",
      "Mean Accuracy achieved :  0.7942795781330293\n",
      "The scores on cross validation are: [0.85325174 0.85301176 0.84085454]\n",
      "Accuracy: 0.85 (+/- 0.01)\n",
      "With the following params : {'C': 0.001, 'solver': 'newton-cg'}\n",
      "Mean Accuracy achieved :  0.849039345215321\n",
      "The scores on cross validation are: [0.85325174 0.85301176 0.84109458]\n",
      "Accuracy: 0.85 (+/- 0.01)\n",
      "With the following params : {'C': 0.001, 'solver': 'lbfgs'}\n",
      "Mean Accuracy achieved :  0.8491193580173692\n",
      "The scores on cross validation are: [0.85313175 0.85433165 0.84241479]\n",
      "Accuracy: 0.85 (+/- 0.01)\n",
      "With the following params : {'C': 0.001, 'solver': 'liblinear'}\n",
      "Mean Accuracy achieved :  0.8499593964311948\n",
      "The scores on cross validation are: [0.88552916 0.88588913 0.8831013 ]\n",
      "Accuracy: 0.88 (+/- 0.00)\n",
      "With the following params : {'C': 0.01, 'solver': 'newton-cg'}\n",
      "Mean Accuracy achieved :  0.8848398609148234\n",
      "The scores on cross validation are: [0.88552916 0.88588913 0.8831013 ]\n",
      "Accuracy: 0.88 (+/- 0.00)\n",
      "With the following params : {'C': 0.01, 'solver': 'lbfgs'}\n",
      "Mean Accuracy achieved :  0.8848398609148234\n",
      "The scores on cross validation are: [0.88552916 0.88576914 0.88346135]\n",
      "Accuracy: 0.88 (+/- 0.00)\n",
      "With the following params : {'C': 0.01, 'solver': 'liblinear'}\n",
      "Mean Accuracy achieved :  0.8849198833176399\n",
      "The scores on cross validation are: [0.89764819 0.89800816 0.89666347]\n",
      "Accuracy: 0.90 (+/- 0.00)\n",
      "With the following params : {'C': 0.1, 'solver': 'newton-cg'}\n",
      "Mean Accuracy achieved :  0.8974399378822616\n",
      "The scores on cross validation are: [0.89776818 0.8975282  0.8969035 ]\n",
      "Accuracy: 0.90 (+/- 0.00)\n",
      "With the following params : {'C': 0.1, 'solver': 'lbfgs'}\n",
      "Mean Accuracy achieved :  0.8973999602835422\n",
      "The scores on cross validation are: [0.89764819 0.89788817 0.8969035 ]\n",
      "Accuracy: 0.90 (+/- 0.00)\n",
      "With the following params : {'C': 0.1, 'solver': 'liblinear'}\n",
      "Mean Accuracy achieved :  0.8974799538840541\n",
      "The scores on cross validation are: [0.8987281  0.89824814 0.89714354]\n",
      "Accuracy: 0.90 (+/- 0.00)\n",
      "With the following params : {'C': 0.5, 'solver': 'newton-cg'}\n",
      "Mean Accuracy achieved :  0.8980399282891742\n",
      "The scores on cross validation are: [0.89800816 0.89860811 0.89774364]\n",
      "Accuracy: 0.90 (+/- 0.00)\n",
      "With the following params : {'C': 0.5, 'solver': 'lbfgs'}\n",
      "Mean Accuracy achieved :  0.898119969893527\n",
      "The scores on cross validation are: [0.8987281  0.89812815 0.89738358]\n",
      "Accuracy: 0.90 (+/- 0.00)\n",
      "With the following params : {'C': 0.5, 'solver': 'liblinear'}\n",
      "Mean Accuracy achieved :  0.8980799442909665\n",
      "The scores on cross validation are: [0.89932805 0.89836813 0.89714354]\n",
      "Accuracy: 0.90 (+/- 0.00)\n",
      "With the following params : {'C': 1, 'solver': 'newton-cg'}\n",
      "Mean Accuracy achieved :  0.8982799090907102\n",
      "The scores on cross validation are: [0.89908807 0.89860811 0.89774364]\n",
      "Accuracy: 0.90 (+/- 0.00)\n",
      "With the following params : {'C': 1, 'solver': 'lbfgs'}\n",
      "Mean Accuracy achieved :  0.898479941095831\n",
      "The scores on cross validation are: [0.89944804 0.89836813 0.89738358]\n",
      "Accuracy: 0.90 (+/- 0.00)\n",
      "With the following params : {'C': 1, 'solver': 'liblinear'}\n",
      "Mean Accuracy achieved :  0.8983999186930144\n",
      "The scores on cross validation are: [0.89848812 0.89836813 0.89738358]\n",
      "Accuracy: 0.90 (+/- 0.00)\n",
      "With the following params : {'C': 3, 'solver': 'newton-cg'}\n",
      "Mean Accuracy achieved :  0.8980799442909665\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-b14334c1e9a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlr_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'solver'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassifiers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mget_best_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-6a92a2f3ed6c>\u001b[0m in \u001b[0;36mget_best_param\u001b[0;34m(class_and_param, train_vectors, train_labels)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m#act_score = compute_f1(classifier(**param), train_vectors, train_labels,val_vectors, val_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The scores on cross validation are:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1289\u001b[0m                       \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1291\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    708\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                     iprint=(verbose > 0) - 1, pgtol=tol, maxiter=max_iter)\n\u001b[0m\u001b[1;32m    711\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0;31m# old scipy doesn't have maxiter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mz0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# Case where we fit the intercept.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \"\"\"\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"toarray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;31m# Fast path for the most common case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_vector\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;31m# csr_matvec or csc_matvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_matvec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_param_model=[]\n",
    "lr_params = ParameterGrid({'C':[1e-4, 1e-3,0.01,0.1,0.5,1,3], 'solver':['newton-cg', 'lbfgs', 'liblinear']})\n",
    "classifiers = [(LogisticRegression, lr_params)]\n",
    "get_best_param(classifiers,X, train_labels) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
